# è¯­ä¹‰åˆ†å‰²é¡¹ç›® (Semantic Segmentation)

åŸºäº PyTorch Lightning å’Œ segmentation_models_pytorch çš„è¯­ä¹‰åˆ†å‰²å®Œæ•´å·¥ç¨‹åŒ–å®ç°ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
project/
â”œâ”€â”€ data/               # æ•°æ®é›†ç›®å½•
â”‚   â””â”€â”€ CamVid/
â”‚       â”œâ”€â”€ train/
â”‚       â”œâ”€â”€ trainannot/
â”‚       â”œâ”€â”€ val/
â”‚       â”œâ”€â”€ valannot/
â”‚       â”œâ”€â”€ test/
â”‚       â””â”€â”€ testannot/
â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ Model.py        # æ¨¡å‹å®šä¹‰å’Œé…ç½®
â”œâ”€â”€ Script
â”‚   â”œâ”€â”€ Train.py        # è®­ç»ƒç›¸å…³å‡½æ•°
â”‚   â”œâ”€â”€ Test.py         # æµ‹è¯•ç›¸å…³å‡½æ•°
â”‚   â”œâ”€â”€ Real.py         # å®é™…åœºæ™¯æ¨ç†ï¼ˆå›¾åƒ/è§†é¢‘/æ‘„åƒå¤´ï¼‰
â”‚   â”œâ”€â”€ Other.py        # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ Datasets.py     # æ•°æ®åŠ è½½ã€é¢„å¤„ç†å’Œå¯è§†åŒ–
â”œâ”€â”€ Main.py             # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ checkpoints/        # è®­ç»ƒcheckpointä¿å­˜
â”œâ”€â”€ exports/            # æ¨¡å‹å¯¼å‡ºæ–‡ä»¶
â””â”€â”€ experiments/        # å®éªŒè®°å½•
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

```bash
pip install -r requirements.txt
```

### 2. å‡†å¤‡æ•°æ®é›†

å°† CamVid æ•°æ®é›†æ”¾ç½®åœ¨ `./data/CamVid/` ç›®å½•ä¸‹ã€‚

### 3. è®­ç»ƒæ¨¡å‹

```python
# ç›´æ¥è¿è¡Œä¸»è®­ç»ƒè„šæœ¬
python Main.py
```

æˆ–è€…è‡ªå®šä¹‰è®­ç»ƒï¼š

```python
from Datasets import get_dataloaders
from Model import create_model
from Train import train_model

# åŠ è½½æ•°æ®
train_loader, valid_loader, test_loader, num_classes = get_dataloaders(
    data_dir="./data/CamVid/",
    batch_size=32,
    num_workers=4
)

# åˆ›å»ºæ¨¡å‹
model = create_model(
    arch="Unet",
    encoder_name="mobileone_s4",
    in_channels=3,
    out_classes=num_classes,
    learning_rate=2e-4
)

# è®­ç»ƒ
trainer = train_model(
    model=model,
    train_loader=train_loader,
    valid_loader=valid_loader,
    max_epochs=50
)
```

### 4. æµ‹è¯•æ¨¡å‹

```python
from Model import load_model_from_checkpoint
from Test import test_from_checkpoint, visualize_test_results

# ä»checkpointæµ‹è¯•
test_metrics = test_from_checkpoint(
    checkpoint_path="./checkpoints/best_model.ckpt",
    test_loader=test_loader
)

# å¯è§†åŒ–ç»“æœ
model = load_model_from_checkpoint("./checkpoints/best_model.ckpt")
visualize_test_results(model, test_loader, num_samples=5)
```

### 5. å®é™…åœºæ™¯æ¨ç†

#### å•å¼ å›¾åƒæµ‹è¯•

```python
from Model import load_model_from_checkpoint
from Real import test_single_image

model = load_model_from_checkpoint("./checkpoints/best_model.ckpt")

result = test_single_image(
    model=model,
    image_path="./test_image.jpg",
    save_path="./result.png"
)
```

#### è§†é¢‘æµ‹è¯•

```python
from Real import test_video

stats = test_video(
    model=model,
    video_path="./input_video.mp4",
    output_path="./output_video.mp4",
    show_window=True
)
```

#### æ‘„åƒå¤´å®æ—¶æµ‹è¯•

```python
from Real import test_camera, test_camera_low_res

# æ–¹å¼1ï¼šè‡ªå®šä¹‰åˆ†è¾¨ç‡ï¼ˆæ¨èï¼‰
test_camera(
    model=model,
    camera_id=0,
    display_size=(640, 480),      # æ˜¾ç¤ºçª—å£å¤§å°
    capture_size=(640, 480),      # æ‘„åƒå¤´æ•è·åˆ†è¾¨ç‡
    show_original_size=True       # åœ¨æ ‡é¢˜æ˜¾ç¤ºåˆ†è¾¨ç‡ä¿¡æ¯
)

# æ–¹å¼2ï¼šå¿«æ·ä½åˆ†è¾¨ç‡æ¨¡å¼ï¼ˆæ›´å¿«æ¨ç†é€Ÿåº¦ï¼‰
test_camera_low_res(
    model=model,
    camera_id=0,
    resolution=(480, 360)  # åŒæ—¶è®¾ç½®æ•è·å’Œæ˜¾ç¤ºåˆ†è¾¨ç‡
)

# æ–¹å¼3ï¼šè¶…ä½åˆ†è¾¨ç‡è·å¾—æœ€é«˜FPS
test_camera_low_res(
    model=model,
    camera_id=0,
    resolution=(320, 240)  # æ¨ç†é€Ÿåº¦æœ€å¿«
)
```

æç¤ºï¼š

- é™ä½åˆ†è¾¨ç‡å¯ä»¥æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ï¼ˆFPSï¼‰
- æ‘„åƒå¤´ 1600x800 â†’ 480x360 å¯ä»¥æå‡çº¦ 3-4 å€æ¨ç†é€Ÿåº¦
- æŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 's' ä¿å­˜å½“å‰å¸§

#### æ‰¹é‡å›¾åƒæµ‹è¯•

```python
from Real import batch_test_images

all_stats = batch_test_images(
    model=model,
    image_dir="./test_images/",
    output_dir="./results/"
)
```

## ğŸ“Š æ¨¡å—è¯´æ˜

### Datasets.py - æ•°æ®å¤„ç†æ¨¡å—

**ä¸»è¦åŠŸèƒ½ï¼š**

- `CamVidDataset`: è‡ªå®šä¹‰æ•°æ®é›†ç±»
- `get_dataloaders()`: è·å–è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ•°æ®åŠ è½½å™¨
- `get_training_augmentation()`: è®­ç»ƒæ•°æ®å¢å¼º
- `get_validation_augmentation()`: éªŒè¯æ•°æ®å¢å¼º
- `visualize_sample()`: å¯è§†åŒ–å•ä¸ªæ ·æœ¬
- `visualize_predictions()`: å¯è§†åŒ–é¢„æµ‹ç»“æœ

### Model.py - æ¨¡å‹å®šä¹‰æ¨¡å—

**ä¸»è¦åŠŸèƒ½ï¼š**

- `SegmentationModel`: PyTorch Lightning å°è£…çš„åˆ†å‰²æ¨¡å‹
- `create_model()`: åˆ›å»ºæ–°æ¨¡å‹
- `load_model_from_checkpoint()`: ä» checkpoint åŠ è½½æ¨¡å‹

**æ”¯æŒçš„æ¨¡å‹æ¶æ„ï¼š**

- Unet
- FPN
- DeepLabV3Plus
- PAN
- LinkNet
- PSPNet
- MAnet

### Train.py - è®­ç»ƒæ¨¡å—

**ä¸»è¦åŠŸèƒ½ï¼š**

- `create_trainer()`: åˆ›å»ºè®­ç»ƒå™¨ï¼ˆæ”¯æŒå¤šç§é…ç½®ï¼‰
- `train_model()`: è®­ç»ƒæ¨¡å‹
- `resume_training()`: ä» checkpoint æ¢å¤è®­ç»ƒ
- `validate_model()`: éªŒè¯æ¨¡å‹
- `get_best_checkpoint()`: è·å–æœ€ä½³ checkpoint

**ç‰¹æ€§ï¼š**

- è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- æ—©åœæœºåˆ¶
- å­¦ä¹ ç‡ç›‘æ§
- TensorBoard æ—¥å¿—
- æ··åˆç²¾åº¦è®­ç»ƒ

### Test.py - æµ‹è¯•æ¨¡å—

**ä¸»è¦åŠŸèƒ½ï¼š**

- `test_model()`: æµ‹è¯•æ¨¡å‹
- `test_from_checkpoint()`: ä» checkpoint æµ‹è¯•
- `visualize_test_results()`: å¯è§†åŒ–æµ‹è¯•ç»“æœ
- `evaluate_metrics()`: è¯¦ç»†è¯„ä¼°æŒ‡æ ‡
- `save_test_results()`: ä¿å­˜æµ‹è¯•ç»“æœ
- `batch_test()`: æ‰¹é‡æµ‹è¯•å¤šä¸ª checkpoint

**è¯„ä¼°æŒ‡æ ‡ï¼š**

- IoU (Intersection over Union)
- F1 Score
- Accuracy
- Precision
- Recall

### Real.py - å®é™…åœºæ™¯æ¨ç†æ¨¡å—

**ä¸»è¦åŠŸèƒ½ï¼š**

- `RealTimeSegmentation`: å®æ—¶åˆ†å‰²æ¨ç†å™¨ç±»
- `test_single_image()`: å•å¼ å›¾åƒæµ‹è¯•ï¼ˆè®°å½•å¤§å°å’Œé€Ÿåº¦ï¼‰
- `test_video()`: è§†é¢‘æ–‡ä»¶æµ‹è¯•
- `test_camera()`: æ‘„åƒå¤´å®æ—¶æµ‹è¯•
- `batch_test_images()`: æ‰¹é‡å›¾åƒæµ‹è¯•

**æ€§èƒ½ç»Ÿè®¡ï¼š**

- æ¨ç†æ—¶é—´ï¼ˆmsï¼‰
- FPSï¼ˆå¸§ç‡ï¼‰
- å›¾åƒå°ºå¯¸
- å¹³å‡/æœ€å°/æœ€å¤§æ¨ç†æ—¶é—´

### Other.py - å·¥å…·å‡½æ•°æ¨¡å—

**ä¸»è¦åŠŸèƒ½ï¼š**

- `save_model_to_dir()`: ä¿å­˜æ¨¡å‹ä¸ºç›®å½•æ ¼å¼
- `save_model_to_onnx()`: å¯¼å‡º ONNX æ¨¡å‹
- `load_model_from_dir()`: ä»ç›®å½•åŠ è½½æ¨¡å‹
- `print_model_info()`: æ‰“å°æ¨¡å‹ä¿¡æ¯
- `count_model_flops()`: è®¡ç®— FLOPs
- `compare_models()`: æ¯”è¾ƒå¤šä¸ªæ¨¡å‹æ€§èƒ½
- `create_experiment_dir()`: åˆ›å»ºå®éªŒç›®å½•
- `get_device_info()`: è·å–è®¾å¤‡ä¿¡æ¯
- `cleanup_checkpoints()`: æ¸…ç†æ—§çš„ checkpoint

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´è®­ç»ƒæµç¨‹

```python
import pytorch_lightning as pl

# è®¾ç½®éšæœºç§å­
pl.seed_everything(42)

# è¿è¡Œä¸»è®­ç»ƒè„šæœ¬
from Main import main
model, metrics = main()
```

### ä» checkpoint æ¢å¤è®­ç»ƒ

```python
from Train import resume_training
from Datasets import get_dataloaders

train_loader, valid_loader, _, _ = get_dataloaders("./data/CamVid/")

trainer = resume_training(
    checkpoint_path="./checkpoints/last.ckpt",
    train_loader=train_loader,
    valid_loader=valid_loader,
    max_epochs=100
)
```

### æ¨¡å‹å¯¹æ¯”å®éªŒ

```python
from Other import compare_models
from Datasets import get_dataloaders

_, _, test_loader, _ = get_dataloaders("./data/CamVid/")

checkpoint_paths = [
    "./checkpoints/model_epoch_20.ckpt",
    "./checkpoints/model_epoch_30.ckpt",
    "./checkpoints/model_epoch_50.ckpt",
]

results = compare_models(checkpoint_paths, test_loader)
```

### å¯¼å‡ºæ¨¡å‹ç”¨äºéƒ¨ç½²

```python
from Model import load_model_from_checkpoint
from Other import save_model_to_onnx, save_model_to_dir

# åŠ è½½æ¨¡å‹
model = load_model_from_checkpoint("./checkpoints/best_model.ckpt")

# å¯¼å‡ºä¸º ONNXï¼ˆç”¨äºæ¨ç†å¼•æ“ï¼‰
save_model_to_onnx(
    model=model.model,
    save_path="./exports/model.onnx",
    input_shape=(1, 3, 480, 640)
)

# å¯¼å‡ºä¸ºç›®å½•æ ¼å¼ï¼ˆç”¨äºç»§ç»­è®­ç»ƒæˆ–è¿ç§»å­¦ä¹ ï¼‰
save_model_to_dir(
    model=model.model,
    save_dir="./exports/saved_model",
    metrics={"test_iou": 0.85}
)
```

## ğŸ”§ é…ç½®è¯´æ˜

### ä¸»è¦é…ç½®å‚æ•°

```python
CONFIG = {
    # æ•°æ®é…ç½®
    "data_dir": "./data/CamVid/",
    "batch_size": 32,
    "num_workers": 4,

    # æ¨¡å‹é…ç½®
    "arch": "Unet",              # æ¨¡å‹æ¶æ„
    "encoder_name": "mobileone_s4",  # ç¼–ç å™¨
    "in_channels": 3,             # è¾“å…¥é€šé“æ•°

    # è®­ç»ƒé…ç½®
    "max_epochs": 50,
    "learning_rate": 2e-4,
    "scheduler_t_max": 50,
    "scheduler_eta_min": 1e-5,

    # è®­ç»ƒå™¨é…ç½®
    "accelerator": "auto",        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
    "devices": 1,                 # ä½¿ç”¨è®¾å¤‡æ•°é‡
    "precision": "16-mixed",      # æ··åˆç²¾åº¦è®­ç»ƒ
}
```

## ğŸ“ˆ å®éªŒè¿½è¸ª

### æŸ¥çœ‹ TensorBoard æ—¥å¿—

```bash
tensorboard --logdir ./checkpoints/camvid_segmentation
```

### æŸ¥çœ‹è®­ç»ƒå†å²

è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ‰€æœ‰æŒ‡æ ‡éƒ½ä¼šè‡ªåŠ¨è®°å½•åˆ° TensorBoardï¼ŒåŒ…æ‹¬ï¼š

- è®­ç»ƒ/éªŒè¯æŸå¤±
- IoU æŒ‡æ ‡
- å­¦ä¹ ç‡å˜åŒ–

## ğŸ› å¸¸è§é—®é¢˜

### 1. CUDA å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆï¼š**

- å‡å° batch_size
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆprecision="16-mixed"ï¼‰

### 2. æ•°æ®åŠ è½½æ…¢

**è§£å†³æ–¹æ¡ˆï¼š**

- å¢åŠ  num_workers
- ä½¿ç”¨ SSD å­˜å‚¨æ•°æ®
- å‡å°‘æ•°æ®å¢å¼ºçš„å¤æ‚åº¦

### 3. æ¨¡å‹è®­ç»ƒä¸æ”¶æ•›

**è§£å†³æ–¹æ¡ˆï¼š**

- æ£€æŸ¥å­¦ä¹ ç‡è®¾ç½®
- ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨
- å¢åŠ è®­ç»ƒè½®æ•°
- æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®

## ğŸ“ å¼€å‘å»ºè®®

1. **å®éªŒç®¡ç†**ï¼šä½¿ç”¨ `create_experiment_dir()` ä¸ºæ¯æ¬¡å®éªŒåˆ›å»ºç‹¬ç«‹ç›®å½•
2. **ç‰ˆæœ¬æ§åˆ¶**ï¼šä½¿ç”¨ Git ç®¡ç†ä»£ç ï¼Œé…ç½®æ–‡ä»¶å•ç‹¬ä¿å­˜
3. **æ—¥å¿—è®°å½•**ï¼šå……åˆ†åˆ©ç”¨ TensorBoard è®°å½•è®­ç»ƒè¿‡ç¨‹
4. **æ¨¡å‹è¯„ä¼°**ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæµ‹è¯•æ¨¡å‹æ³›åŒ–èƒ½åŠ›
5. **ä»£ç è§„èŒƒ**ï¼šéµå¾ª PEP 8 ä»£ç é£æ ¼

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼
